{
    "model_name": "gpt_model",
    "vocab_size": 50257,
    "embedding_size": 768,
    "num_heads": 12,
    "num_layers": 12,
    "max_position_embeddings": 1024,
    "dropout_rate": 0.1,
    "learning_rate": 5e-5,
    "batch_size": 8,
    "num_epochs": 10
}
